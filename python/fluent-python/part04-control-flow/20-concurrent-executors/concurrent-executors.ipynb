{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With threads, 99% of the use cases an application programmer is likely to run into is the simple pattern of \"spawning a bunch of independent threads and collecting the results in a queue\". This chapter focuses on the `concurrent.futures.Executor` classes that encapsulate this pattern. \n",
    "\n",
    "We will also learn the concept of `futures` ‚Äî objects representing the asynchronous execution of an operation (and foundational to the `asyncio` package), similar to JavaScript's `promises`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concurrent Web Downloads\n",
    "\n",
    "<span style=\"color:skyblue\">***Concurrency is essential for efficient network I/O: instead of idly waiting for remote machines, the application should do something else until a response comes back***</span>.\n",
    "\n",
    "We will learn 3 scripts to download 20 flags from the web: \n",
    "- `flags.py`: run downloads sequentially\n",
    "- `flags_threadpool.py`: make concurrent downloads using `concurrent.futures`\n",
    "- `flags_asyncio.py`: make concurrent downloads using `asyncio`\n",
    "\n",
    "The sequential code will take the longest, while the 2 others make similar perfomance with much shorter time. And also, the order of the flags downloaded will be different in each code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A sequential download script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BD BR CD CN DE EG ET FR ID IN IR JP MX NG PH PK RU TR US VN \n",
      "20 downloads in 15.12s\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from pathlib import Path\n",
    "from typing import Callable\n",
    "\n",
    "import httpx\n",
    "\n",
    "POP20_CC = ('CN IN US ID BR PK NG BD RU JP '\n",
    "            'MX PH VN ET EG DE IR TR CD FR').split()  # country codes for the 20 most populous countries\n",
    "\n",
    "BASE_URL = 'https://www.fluentpython.com/data/flags'  # The directory with the flag images\n",
    "DEST_DIR = Path('downloaded')                         # Local directory where the images are saved.\n",
    "\n",
    "def save_flag(img: bytes, filename: str) -> None:\n",
    "    \"\"\"\n",
    "    Save the img bytes to filename in the DEST_DIR\n",
    "    \"\"\"\n",
    "    (DEST_DIR / filename).write_bytes(img)\n",
    "\n",
    "def get_flag(cc: str) -> bytes:\n",
    "    \"\"\"\n",
    "    Given a country code, build the URL and download the image, \n",
    "    returning the binary contents of the response.\n",
    "    \"\"\"\n",
    "    url = f'{BASE_URL}/{cc}/{cc}.gif'.lower()\n",
    "    resp = httpx.get(url, timeout=6.1,  # adding time out to avoid blocking for too long\n",
    "                    follow_redirects=True)  # HTTPX does not follow redirects by default\n",
    "    resp.raise_for_status()  # raises an exception if the HTTP status is not in the 2XX range\n",
    "    return resp.content\n",
    "\n",
    "def download_many(cc_list: list[str]) -> int:\n",
    "    \"\"\"\n",
    "    Key function to compare with the concurrent implementations\n",
    "    \"\"\"\n",
    "    for cc in sorted(cc_list): # Loop over the list of country codes in alphabetical order\n",
    "        image = get_flag(cc)\n",
    "        save_flag(image, f'{cc}.gif')\n",
    "        print(cc, end=' ', flush=True)  # Display the country code after the image is downloaded\n",
    "    return len(cc_list)\n",
    "\n",
    "def main(downloader: Callable[[list[str]], int]) -> None:\n",
    "    \"\"\"\n",
    "    main must be called with the function that will make the downloads; \n",
    "    that way, we can use main as a library function with other \n",
    "    implementations of download_many in the threadpool and ascyncio examples\n",
    "    \"\"\"\n",
    "    DEST_DIR.mkdir(exist_ok=True)\n",
    "    t0 = time.perf_counter() # Record the elapsed time after running the downloader function\n",
    "    count = downloader(POP20_CC)\n",
    "    elapsed = time.perf_counter() - t0\n",
    "    print(f'\\n{count} downloads in {elapsed:.2f}s')\n",
    "\n",
    "main(download_many)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üóíÔ∏è Note: Crucially, `HTTPX` provides synchronous and asynchronous APIs, so we can use it in all HTTP client examples in this chapter and the next. Python's standard library provides the `urllib.request` module, but its API is synchronous only, and is not user friendly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading with `concurrent.futures`\n",
    "\n",
    "The main features of the `concurrent.futures` package are the `ThreadPoolExecutor` and `ProcessPoolExecutor` classes, which implement an API to submit callables for execution in different threads or processes, respectively. The classes transparently manage a pool of worker threads or processes, and queues to distribute jobs and collect results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CD CN EG ID FR ET BD MX NG BR JP IN PK PH IR RU TR US VN DE \n",
      "20 downloads in 0.42s\n"
     ]
    }
   ],
   "source": [
    "from concurrent import futures\n",
    "\n",
    "# Use the `save_flag`, `get_flag`, `main` functions from the sequential code above\n",
    "\n",
    "def download_one(cc: str):\n",
    "    \"\"\"\n",
    "    Function to download a single image; this is what \n",
    "    each worker will execute.\n",
    "    \"\"\"\n",
    "    image = get_flag(cc)\n",
    "    save_flag(image, f'{cc}.gif')\n",
    "    print(cc, end=' ', flush=True)\n",
    "    return cc\n",
    "\n",
    "def download_many_thread_pool(cc_list: list[str]) -> int:\n",
    "    # Below, we instantiate the ThreadPoolExecutor as a context manager; \n",
    "    # the `executor.__exit__` method will call `executor.shutdown(wait=True)`, \n",
    "    # which will block until all threads are done.\n",
    "    with futures.ThreadPoolExecutor() as executor:\n",
    "        # The `map` method is similar to the built-in `map`,\n",
    "        # except that the `download_one` function will be called \n",
    "        # concurrently from multiple threads; \n",
    "        # it returns a generator that you can iterate to retrieve \n",
    "        # the value returned by each function call‚Äîin this case,\n",
    "        # each call to download_one will return a country code.\n",
    "        res = executor.map(download_one, sorted(cc_list))\n",
    "\n",
    "    # Fianlly we return the number of results obtained.\n",
    "    # If any of the threaded calls raises an exception, \n",
    "    # that exception is raised here when the implicit `next()` call \n",
    "    # inside the list constructor tries to retrieve the corresponding \n",
    "    # return value from the iterator returned by `executor.map`.\n",
    "    return len(list(res))\n",
    "\n",
    "main(download_many_thread_pool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üóíÔ∏è Note: `ThreadPoolExecutor`'s most important argument is the `max_workers` which is the max number of worker threads to be executed. By default, `max_workers = min(32, os.cpu_count() + 4)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Where Are the `Future`s?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Futures are core components of `concurrent.futures` and of `asyncio`, but as users of these libraries we sometimes don‚Äôt see them (they run behind the scene).\n",
    "\n",
    "Since Python 3.4, there are two classes named `Future` in the standard library: `concurrent.futures.Future` and `asyncio.Future`. They serve the same purpose: \n",
    "<span style=\"color:skyblue\">***an instance of either `Future` class represents a deferred computation that may or may not have completed. `Future`s encapsulate pending operations so that we can put them in queues, check whether they are done, and retrieve results (or exceptions) when they become available.***</span>. (Similar to the `Deferred` class in `Twisted`, the `Future` class in `Tornado`, and `Promise` in modern JavaScript).\n",
    "\n",
    "üóíÔ∏è Note: <span style=\"color:orange\">*Programmers should not create or change the state of a `Future`:\n",
    "they are meant to be instantiated exclusively by the concurrency framework, be it `concurrent.futures` or `asyncio`*</span>. Here is why: a `Future` represents something that will eventually run, therefore it must be scheduled to run, and that‚Äôs the job of the framework. In particular, `concurrent.futures.Future` instances are created only as the result of submitting a callable for execution with a `concurrent.futures.Executor` subclass. For example, the `Executor.submit()` method takes a callable, schedules it to run, and returns a `Future`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look more closely into `Future` by replacing `executor.map` with `executor.submit` and `futures.as_completed` in the `download_many` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scheduled for BR: <Future at 0x7110b7994f10 state=running>\n",
      "Scheduled for CN: <Future at 0x7110b684b4d0 state=running>\n",
      "Scheduled for ID: <Future at 0x7110b684a150 state=running>\n",
      "Scheduled for IN: <Future at 0x7110b6dd2810 state=pending>\n",
      "Scheduled for US: <Future at 0x7110b68788d0 state=pending>\n",
      "BR CN <Future at 0x7110b7994f10 state=finished returned str> result: 'BR'\n",
      "<Future at 0x7110b684b4d0 state=finished returned str> result: 'CN'\n",
      "ID <Future at 0x7110b684a150 state=finished returned str> result: 'ID'\n",
      "IN <Future at 0x7110b6dd2810 state=finished returned str> result: 'IN'\n",
      "US <Future at 0x7110b68788d0 state=finished returned str> result: 'US'\n",
      "\n",
      "5 downloads in 0.39s\n"
     ]
    }
   ],
   "source": [
    "def download_many_futures(cc_list: list[str]) -> int:\n",
    "    cc_list = cc_list[:5] # use only the top five most populous countries\n",
    "    with futures.ThreadPoolExecutor(max_workers=3) as executor:  # Set max_workers to 3 \n",
    "                                                                 # so we can see pending futures in the output\n",
    "        to_do: list[futures.Future] = []\n",
    "        for cc in sorted(cc_list):  # Iterate over country codes alphabetically, \n",
    "                                    # to make it clear that results will arrive out of order.\n",
    "            future = executor.submit(download_one, cc)  # executor.submit schedules the \n",
    "                                                        # callable to be executed, and returns a future representing this pending operation.\n",
    "            to_do.append(future)  # Store each future so we can later retrieve them with as_completed\n",
    "            print(f'Scheduled for {cc}: {future}')  # Display a message with the country code and the respective future\n",
    "        \n",
    "        for count, future in enumerate(futures.as_completed(to_do), 1):  # as_completed yields futures as they are completed\n",
    "            res: str = future.result()  # Get the result of this future\n",
    "            print(f'{future} result: {res!r}') # Display the future and its result.\n",
    "    \n",
    "    return count\n",
    "\n",
    "main(download_many_futures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the output of `download_many_futures`, we can see that \n",
    "- The futures are scheduled in alphabetical order; the `repr()` of a future shows its state: the first three are running, because there are three worker threads.\n",
    "- The last two futures are pending, waiting for worker threads.\n",
    "- Running the function several times will give different output orders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Launching Processes with `concurrent.futures`\n",
    "\n",
    "The package enables parallel computation on multicore machines because it supports distributing work among multiple Python processes using the `ProcessPoolExecutor` class. Both `ProcessPoolExecutor` and `ThreadPoolExecutor` implement the `Executor`\n",
    "interface, so it‚Äôs easy to switch from a thread-based to a process-based solution using `concurrent.futures`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID BR FRDE  EG ETIN  BD CN JP IR CD MX NG PK US RU PH VN TR \n",
      "20 downloads in 0.44s\n"
     ]
    }
   ],
   "source": [
    "def download_many_process_pool(cc_list: list[str]) -> int:\n",
    "    # below we use the ProcessPoolExecutor instead of ThreadPoolExecutor\n",
    "    with futures.ProcessPoolExecutor() as executor:\n",
    "        res = executor.map(download_one, sorted(cc_list))\n",
    "\n",
    "    return len(list(res))\n",
    "\n",
    "main(download_many_process_pool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multicore Prime Checker Redux\n",
    "In chapter 19, we wrote a program that checked the primality of some large numbers using `multiprocessing` (`procs.py`). Let's do the same thing using `ProcessPoolExecutor`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking 20 numbers with 12 processes:\n",
      "9999999999999999     0.000035s\n",
      "9999999999999917  P  4.447117s\n",
      "7777777777777777     0.000018s\n",
      "7777777777777753  P  4.263446s\n",
      "7777777536340681     3.885129s\n",
      "6666667141414921     4.045834s\n",
      "6666666666666719  P  3.815436s\n",
      "6666666666666666     0.000006s\n",
      "5555555555555555     0.000019s\n",
      "5555555555555503  P  3.729342s\n",
      "5555553133149889     3.923309s\n",
      "4444444488888889     3.494794s\n",
      "4444444444444444     0.000001s\n",
      "4444444444444423  P  3.373819s\n",
      "3333335652092209     3.317096s\n",
      "3333333333333333     0.000003s\n",
      "3333333333333301  P  3.020736s\n",
      " 299593572317531  P  1.151811s\n",
      " 142702110479723  P  0.707913s\n",
      "               2  P  0.000002s\n",
      "Total time: 4.50s\n"
     ]
    }
   ],
   "source": [
    "from concurrent import futures # No need to import multiprocessing, SimpleQueue... \n",
    "                            # since `concurrent.futures` hides all that\n",
    "from time import perf_counter\n",
    "from typing import NamedTuple\n",
    "\n",
    "import math\n",
    "\n",
    "\n",
    "PRIME_FIXTURE = [\n",
    "    (2, True),\n",
    "    (142702110479723, True),\n",
    "    (299593572317531, True),\n",
    "    (3333333333333301, True),\n",
    "    (3333333333333333, False),\n",
    "    (3333335652092209, False),\n",
    "    (4444444444444423, True),\n",
    "    (4444444444444444, False),\n",
    "    (4444444488888889, False),\n",
    "    (5555553133149889, False),\n",
    "    (5555555555555503, True),\n",
    "    (5555555555555555, False),\n",
    "    (6666666666666666, False),\n",
    "    (6666666666666719, True),\n",
    "    (6666667141414921, False),\n",
    "    (7777777536340681, False),\n",
    "    (7777777777777753, True),\n",
    "    (7777777777777777, False),\n",
    "    (9999999999999917, True),\n",
    "    (9999999999999999, False),\n",
    "]\n",
    "\n",
    "NUMBERS = [n for n, _ in PRIME_FIXTURE]\n",
    "\n",
    "def is_prime(n: int) -> bool:\n",
    "    if n < 2:\n",
    "        return False\n",
    "    if n == 2:\n",
    "        return True\n",
    "    if n % 2 == 0:\n",
    "        return False\n",
    "\n",
    "    root = math.isqrt(n)\n",
    "    for i in range(3, root + 1, 2):\n",
    "        if n % i == 0:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "class PrimeResult(NamedTuple):\n",
    "    n: int\n",
    "    flag: bool\n",
    "    elapsed: float\n",
    "\n",
    "def check(n: int) -> PrimeResult:\n",
    "    t0 = perf_counter()\n",
    "    res = is_prime(n)\n",
    "    return PrimeResult(n, res, perf_counter() - t0)\n",
    "\n",
    "def main() -> None:\n",
    "    executor = futures.ProcessPoolExecutor()\n",
    "    actual_workers = executor._max_workers  # used to show the number of workers used\n",
    "\n",
    "    print(f'Checking {len(NUMBERS)} numbers with {actual_workers} processes:')\n",
    "\n",
    "    t0 = perf_counter()\n",
    "\n",
    "    numbers = sorted(NUMBERS, reverse=True)  # Sort the numbers to be checked in descending order\n",
    "    with executor:  # Use the executor as a context manager\n",
    "        # below, the `executor.map` call returns the `PrimeResult` instances returned \n",
    "        # by `check` in the same order as the `numbers` arguments\n",
    "        for n, prime, elapsed in executor.map(check, numbers):\n",
    "            label = 'P' if prime else ' '\n",
    "            print(f'{n:16}  {label} {elapsed:9.6f}s')\n",
    "\n",
    "    time = perf_counter() - t0\n",
    "    print(f'Total time: {time:.2f}s')\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üóíÔ∏è Note: The ordering of the output of `procs.py` which uses `multiprocessing` in chapter 19 is heavily influenced by the difficulty in checking whether each number is a prime. In contrast, the results appearing using `ProcessPoolExecutor` above are in strict descending order. The reasons is that `executor.map(check, numbers)` returns the result in the same order as the `numbers` are given, and while the process checking `9999999999999917` takes very long, all other processes will be checking other number, and when the worker in charge of `9999999999999917` finally determines that‚Äôs a prime, all the other processes have completed their last jobs, so the results appear immediately after."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimenting with `Executor.map`\n",
    "\n",
    "To learn more about how concurrent programs behave, let's study another example of the `map` method of `ThreadPoolExecutor` with 3 workers running 5 callables that output timestamped messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:19:25] Script starting.\n",
      "[16:19:25] loiter(0): doing nothing for 0s...\n",
      "[16:19:25] loiter(0): done.\n",
      "[16:19:25] \tloiter(1): doing nothing for 1s...\n",
      "[16:19:25] \t\tloiter(2): doing nothing for 2s...\n",
      "[16:19:25] \t\t\tloiter(3): doing nothing for 3s...\n",
      "[16:19:25] results: <generator object Executor.map.<locals>.result_iterator at 0x7110b68f9340>\n",
      "[16:19:25] Waiting for individual results:\n",
      "[16:19:25] result 0: 0\n",
      "[16:19:26] \tloiter(1): done.\n",
      "[16:19:26] \t\t\t\tloiter(4): doing nothing for 4s...\n",
      "[16:19:26] result 1: 10\n",
      "[16:19:27] \t\tloiter(2): done.\n",
      "[16:19:27] result 2: 20\n",
      "[16:19:28] \t\t\tloiter(3): done.\n",
      "[16:19:28] result 3: 30\n",
      "[16:19:30] \t\t\t\tloiter(4): done.\n",
      "[16:19:30] result 4: 40\n"
     ]
    }
   ],
   "source": [
    "from time import sleep, strftime\n",
    "from concurrent import futures\n",
    "\n",
    "def display(*args):\n",
    "    \"\"\"\n",
    "    Simply prints all the arguments it gets, preceded by a timestamp\n",
    "    \"\"\"\n",
    "    print(strftime('[%H:%M:%S]'), end=' ')\n",
    "    print(*args)\n",
    "\n",
    "def loiter(n):\n",
    "    \"\"\"\n",
    "    display a message when it starts, sleep for n seconds,\n",
    "    then display a message when it ends\n",
    "    \"\"\"\n",
    "    msg = '{}loiter({}): doing nothing for {}s...'\n",
    "    display(msg.format('\\t'*n, n, n))\n",
    "    sleep(n)\n",
    "    msg = '{}loiter({}): done.'\n",
    "    display(msg.format('\\t'*n, n))\n",
    "    return n * 10  # loiter returns n * 10 so we can see how to collect results\n",
    "\n",
    "def main():\n",
    "    display('Script starting.')\n",
    "    executor = futures.ThreadPoolExecutor(max_workers=3)  # three threads running five callables\n",
    "    results = executor.map(loiter, range(5))  # Submit five tasks to the executor. Since \n",
    "                                            # there are only three threads, only three\n",
    "                                            # of those tasks will start immediately: \n",
    "                                            # the calls loiter(0), loiter(1), and loiter(2)\n",
    "                                            # this is a nonblocking call.\n",
    "    display('results:', results)  # Immediately display the results of \n",
    "                                # invoking `executor.map`: it‚Äôs a generator\n",
    "    display('Waiting for individual results:')\n",
    "    for i, result in enumerate(results):  # The enumerate call in the `for` loop will implicitly invoke `next(results)`, which\n",
    "                                        #in turn will invoke `_f.result()` on the (internal) `_f` future representing the first\n",
    "                                        # call, `loiter(0)`. The `result` method will block until the future is done, therefore\n",
    "                                        # each iteration in this loop will have to wait for the next `result` to be ready.\n",
    "        display(f'result {i}: {result}')\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Executor.map` function is easy to use, but often it‚Äôs preferable to get the results as they are ready, regardless of the order they were submitted. To do that, we need a combination of the `Executor.submit` method and the `futures.as_completed` function. The combination of `executor.submit` and `futures.as_completed` is more flexible than `executor.map` because \n",
    "- you can submit different callables and arguments, while `executor.map` is designed\n",
    "to run the same callable on the different arguments.\n",
    "- the set of futures you pass to `futures.as_completed` may come from more than one executor‚Äîperhaps some were created by a `ThreadPoolExecutor` instance, while others are from a `ProcessPoolExecutor`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloads with Progress Display and Error Handling\n",
    "\n",
    "Let's rewrite the downloading flags program with error handlings to make them easier to read and to contrast the structure of the three approaches: *sequential*, *threaded*, and *asynchronous*. The code are in `flags2/`\n",
    "\n",
    "- `flags2_common.py`: This module contains common functions and settings used by all flags2 examples, including a main function, which takes care of command-line parsing, timing, and reporting results.\n",
    "- `flags2_sequential.py`: A sequential HTTP client with proper error handling and progress bar display. Its `download_one` function is also used by `flags2_threadpool.py`.\n",
    "- `flags2_threadpool.py`: Concurrent HTTP client based on `futures.ThreadPoolExecutor` to demonstrate error handling and integration of the progress bar.\n",
    "- `flags2_asyncio.py`: Same functionality as the previous example, but implemented with `asyncio` and `httpx`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: flags2_threadpool.py [-h] [-a] [-e] [-l N] [-m CONCURRENT] [-s LABEL]\n",
      "                            [-v]\n",
      "                            [CC ...]\n",
      "\n",
      "Download flags for country codes. Default: top 20 countries by population.\n",
      "\n",
      "positional arguments:\n",
      "  CC                    country code or 1st letter (eg. B for BA...BZ)\n",
      "\n",
      "options:\n",
      "  -h, --help            show this help message and exit\n",
      "  -a, --all             get all available flags (AD to ZW)\n",
      "  -e, --every           get flags for every possible code (AA...ZZ)\n",
      "  -l N, --limit N       limit to N first codes\n",
      "  -m CONCURRENT, --max_req CONCURRENT\n",
      "                        maximum concurrent requests (default=30)\n",
      "  -s LABEL, --server LABEL\n",
      "                        Server to hit; one of DELAY, ERROR, LOCAL, REMOTE\n",
      "                        (default=LOCAL)\n",
      "  -v, --verbose         output detailed progress info\n"
     ]
    }
   ],
   "source": [
    "!python3 flags2/flags2_threadpool.py -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REMOTE site: https://www.fluentpython.com/data/flags\n",
      "Searching for 20 flags: from BD to VN\n",
      "1 connection will be used.\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:09<00:00,  2.09it/s]\n",
      "--------------------\n",
      " 20 flags downloaded.\n",
      "Elapsed time: 9.57s\n"
     ]
    }
   ],
   "source": [
    "!python3 flags2/flags2_sequential.py -s REMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REMOTE site: https://www.fluentpython.com/data/flags\n",
      "Searching for 20 flags: from BD to VN\n",
      "5 concurrent connections will be used.\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:05<00:00,  3.85it/s]\n",
      "--------------------\n",
      " 20 flags downloaded.\n",
      "Elapsed time: 5.23s\n"
     ]
    }
   ],
   "source": [
    "!python flags2/flags2_threadpool.py -s REMOTE -m 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REMOTE site: https://www.fluentpython.com/data/flags\n",
      "Searching for 20 flags: from BD to VN\n",
      "10 concurrent connections will be used.\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:02<00:00,  9.35it/s]\n",
      "--------------------\n",
      " 20 flags downloaded.\n",
      "Elapsed time: 2.15s\n"
     ]
    }
   ],
   "source": [
    "!python flags2/flags2_asyncio.py -s REMOTE -m 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further Reading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
